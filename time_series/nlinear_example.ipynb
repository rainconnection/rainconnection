{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c08b30-6ef1-42cc-be3a-6a50498fc606",
   "metadata": {},
   "source": [
    "### kaggle playground private 2등\n",
    "* 간단한 모형 구현연습하기에 playground는 좋은 것 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc542fef-0819-4e1f-8bdf-9335fee722ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import functions\n",
    "import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8795e7-e3dd-4027-818e-5ad797792042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date    country         store  \\\n",
       "0   0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1   1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2   2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3   3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4   4  2017-01-01  Argentina  Kaggle Learn   \n",
       "\n",
       "                                          product  num_sold  \n",
       "0               Using LLMs to Improve Your Coding        63  \n",
       "1                   Using LLMs to Train More LLMs        66  \n",
       "2  Using LLMs to Win Friends and Influence People         9  \n",
       "3      Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                      Using LLMs to Write Better        49  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../copy-of-forecasting-mini-course-sales/train.csv')\n",
    "test = pd.read_csv('../copy-of-forecasting-mini-course-sales/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df59db9",
   "metadata": {
    "papermill": {
     "duration": 0.073496,
     "end_time": "2024-03-26T08:38:07.711354",
     "exception": false,
     "start_time": "2024-03-26T08:38:07.637858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['date']=pd.to_datetime(train['date'])\n",
    "test['date']=pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1806166",
   "metadata": {
    "papermill": {
     "duration": 0.034032,
     "end_time": "2024-03-26T08:38:07.753353",
     "exception": false,
     "start_time": "2024-03-26T08:38:07.719321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    366\n",
       "2017    365\n",
       "2018    365\n",
       "2019    365\n",
       "2021    365\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([x.year for x in train['date'].unique()]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a151be76",
   "metadata": {
    "papermill": {
     "duration": 0.016856,
     "end_time": "2024-03-26T08:38:07.778283",
     "exception": false,
     "start_time": "2024-03-26T08:38:07.761427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = train.loc[(train['date'] != '2020-02-29')] # 큰 의미는 없네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049ec98a",
   "metadata": {
    "papermill": {
     "duration": 0.150276,
     "end_time": "2024-03-26T08:38:07.936827",
     "exception": false,
     "start_time": "2024-03-26T08:38:07.786551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "column_list = ['country','store','product']\n",
    "for c in column_list:\n",
    "    label_encoders[c] = LabelEncoder()\n",
    "    label_encoders[c].fit(train[c])\n",
    "    \n",
    "    train[c] = label_encoders[c].transform(train[c])\n",
    "    test[c] = label_encoders[c].transform(test[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1f200e",
   "metadata": {
    "papermill": {
     "duration": 2.266035,
     "end_time": "2024-03-26T08:38:10.210902",
     "exception": false,
     "start_time": "2024-03-26T08:38:07.944867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(x, yrain_years):\n",
    "    x = x.sort_values('date')['num_sold'].values.tolist()\n",
    "    window_size = 365\n",
    "    full_size = window_size*(train_years+1)\n",
    "    train_size = window_size*train_years\n",
    "    \n",
    "    trey = []\n",
    "    for i in range(len(x)-full_size+1):\n",
    "        trey.append([x[i:i+train_size], x[i+train_size:i+full_size]])\n",
    "    return trey\n",
    "train_years = 3\n",
    "reshaped = pd.concat([train, test]).groupby(['country', 'store', 'product']).apply(lambda x : data_process(x[['date','num_sold']], train_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4835a880",
   "metadata": {
    "papermill": {
     "duration": 0.01707,
     "end_time": "2024-03-26T08:38:10.236119",
     "exception": false,
     "start_time": "2024-03-26T08:38:10.219049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test : reshaped[0][0][0][-1][0]\n",
    "# test : reshaped[0][0][0][-366][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88aa17df",
   "metadata": {
    "papermill": {
     "duration": 10.003823,
     "end_time": "2024-03-26T08:38:20.248596",
     "exception": false,
     "start_time": "2024-03-26T08:38:10.244773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 12495.94it/s]\n"
     ]
    }
   ],
   "source": [
    "feature = []\n",
    "target = []\n",
    "test_feature = []\n",
    "test_target = []\n",
    "for values in tqdm(reshaped.values):\n",
    "    for value in values[:-365]:\n",
    "        feature.append(value[0])\n",
    "        target.append(value[1])\n",
    "        \n",
    "    test_feature.append(values[-1][0])\n",
    "    test_target.append(values[-1][1])\n",
    "feature = pd.DataFrame(feature)\n",
    "target = pd.DataFrame(target)\n",
    "test_feature = tensor(test_feature)\n",
    "test_target = tensor(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df12513f",
   "metadata": {
    "papermill": {
     "duration": 0.415249,
     "end_time": "2024-03-26T08:38:20.672920",
     "exception": false,
     "start_time": "2024-03-26T08:38:20.257671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feature = feature.sample(int(feature.shape[0]*0.9), random_state = 1004)\n",
    "idx = train_feature.index\n",
    "train_feature = tensor(train_feature.values)\n",
    "train_target = tensor(target.loc[idx].values)\n",
    "\n",
    "valid_feature = tensor(feature.drop(idx).values)\n",
    "valid_target = tensor(target.drop(idx).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f6ee15",
   "metadata": {
    "papermill": {
     "duration": 0.025376,
     "end_time": "2024-03-26T08:38:20.707885",
     "exception": false,
     "start_time": "2024-03-26T08:38:20.682509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(train_feature, train_target), batch_size = 2**10, shuffle = True)\n",
    "valid_loader = DataLoader(TensorDataset(valid_feature, valid_target), batch_size = 2**25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb5dc166",
   "metadata": {
    "papermill": {
     "duration": 166.136816,
     "end_time": "2024-03-26T08:41:06.926478",
     "exception": false,
     "start_time": "2024-03-26T08:38:20.789662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  1.2098925922859394  & valid loss :  0.34467998147010803  & epoch :  1  & time 1.3909635543823242\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.1163167437123748  & valid loss :  0.05337835103273392  & epoch :  2  & time 2.787266254425049\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.04073857112542389  & valid loss :  0.03413711115717888  & epoch :  3  & time 4.155574560165405\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.0312984124654337  & valid loss :  0.029325103387236595  & epoch :  4  & time 6.196982383728027\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.028353015791601325  & valid loss :  0.02718854509294033  & epoch :  5  & time 7.604169845581055\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.026742050410382932  & valid loss :  0.025927435606718063  & epoch :  6  & time 9.003443002700806\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.025320426479881863  & valid loss :  0.024746853858232498  & epoch :  7  & time 10.398537635803223\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02433924655173315  & valid loss :  0.02380683831870556  & epoch :  8  & time 11.80470609664917\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.023453428177952516  & valid loss :  0.023146819323301315  & epoch :  9  & time 13.684958934783936\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.022896265778278527  & valid loss :  0.022715548053383827  & epoch :  10  & time 15.101737260818481\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02228009516224999  & valid loss :  0.02278830297291279  & epoch :  11  & time 16.495325803756714\n",
      "train loss :  0.021768169925723634  & valid loss :  0.02163943648338318  & epoch :  12  & time 17.897781372070312\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02142635221225696  & valid loss :  0.021347898989915848  & epoch :  13  & time 19.81174612045288\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02120169577766712  & valid loss :  0.021195707842707634  & epoch :  14  & time 21.215530395507812\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02100381972417103  & valid loss :  0.02096840739250183  & epoch :  15  & time 22.61011266708374\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.020749859171084146  & valid loss :  0.02069254219532013  & epoch :  16  & time 24.00945258140564\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.020544578001413228  & valid loss :  0.020555762574076653  & epoch :  17  & time 25.899542331695557\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.020365949296665447  & valid loss :  0.020296938717365265  & epoch :  18  & time 27.309720516204834\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02016551775748628  & valid loss :  0.02015804871916771  & epoch :  19  & time 28.55000114440918\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.02008772825579516  & valid loss :  0.020045030862092972  & epoch :  20  & time 29.945074796676636\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01990735683010898  & valid loss :  0.019819095730781555  & epoch :  21  & time 31.82831621170044\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.019591800665794773  & valid loss :  0.0196219515055418  & epoch :  22  & time 33.23448991775513\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.019472747960246842  & valid loss :  0.019513221457600594  & epoch :  23  & time 34.623268365859985\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.019288403545842405  & valid loss :  0.019411548972129822  & epoch :  24  & time 36.02485728263855\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.019173459095909562  & valid loss :  0.01939365267753601  & epoch :  25  & time 37.91810941696167\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01899135843203273  & valid loss :  0.01915157027542591  & epoch :  26  & time 39.331292152404785\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01889770336589905  & valid loss :  0.018934210762381554  & epoch :  27  & time 40.747466802597046\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.018795013872868367  & valid loss :  0.018882477656006813  & epoch :  28  & time 42.1312518119812\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01860429607355814  & valid loss :  0.01870345138013363  & epoch :  29  & time 44.01752018928528\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.018441550205654925  & valid loss :  0.01941012777388096  & epoch :  30  & time 45.426084995269775\n",
      "train loss :  0.01842743460460114  & valid loss :  0.018391385674476624  & epoch :  31  & time 46.83748126029968\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.018155848417938207  & valid loss :  0.01822907291352749  & epoch :  32  & time 48.24110007286072\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.018033554496286606  & valid loss :  0.018143361434340477  & epoch :  33  & time 50.266313552856445\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017985529871589818  & valid loss :  0.018095165491104126  & epoch :  34  & time 51.677897453308105\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017903465264528417  & valid loss :  0.018171710893511772  & epoch :  35  & time 52.941182374954224\n",
      "train loss :  0.017771966294315565  & valid loss :  0.01793239638209343  & epoch :  36  & time 54.32482957839966\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01773338132875812  & valid loss :  0.017890799790620804  & epoch :  37  & time 55.70940709114075\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017695774475974854  & valid loss :  0.01786406710743904  & epoch :  38  & time 57.600260734558105\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01766554968834318  & valid loss :  0.017897887155413628  & epoch :  39  & time 58.99284791946411\n",
      "train loss :  0.017614765955027253  & valid loss :  0.017855973914265633  & epoch :  40  & time 60.39202427864075\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01761896903019825  & valid loss :  0.01779450848698616  & epoch :  41  & time 61.77657341957092\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01759403704575522  & valid loss :  0.017758961766958237  & epoch :  42  & time 63.69404196739197\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017587808896191194  & valid loss :  0.017766248434782028  & epoch :  43  & time 65.13223910331726\n",
      "train loss :  0.017528060209815132  & valid loss :  0.017713988199830055  & epoch :  44  & time 66.52840971946716\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017504262328436625  & valid loss :  0.01774555630981922  & epoch :  45  & time 67.9115903377533\n",
      "train loss :  0.017498458827228128  & valid loss :  0.017694523558020592  & epoch :  46  & time 69.78824281692505\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017490133897598546  & valid loss :  0.01769472099840641  & epoch :  47  & time 71.19242072105408\n",
      "train loss :  0.017486238955005333  & valid loss :  0.017691269516944885  & epoch :  48  & time 72.5842113494873\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01748020082276664  & valid loss :  0.017685048282146454  & epoch :  49  & time 73.96165657043457\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017482377885605183  & valid loss :  0.01768370531499386  & epoch :  50  & time 75.84101843833923\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017473072662044856  & valid loss :  0.01767854392528534  & epoch :  51  & time 77.10630702972412\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01747249071611864  & valid loss :  0.017676785588264465  & epoch :  52  & time 78.50687718391418\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017468892060425966  & valid loss :  0.017676999792456627  & epoch :  53  & time 79.89615273475647\n",
      "train loss :  0.01746795269205442  & valid loss :  0.017676543444395065  & epoch :  54  & time 81.78540253639221\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017467500734878783  & valid loss :  0.017675545066595078  & epoch :  55  & time 83.47302436828613\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017466799431385276  & valid loss :  0.01767534576356411  & epoch :  56  & time 84.8702003955841\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017466535771603387  & valid loss :  0.017675239592790604  & epoch :  57  & time 86.25638175010681\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01746636714853061  & valid loss :  0.017675228416919708  & epoch :  58  & time 87.68716096878052\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017466275901175  & valid loss :  0.017675219103693962  & epoch :  59  & time 89.57780742645264\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01746622181649251  & valid loss :  0.017675215378403664  & epoch :  60  & time 90.99099779129028\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.017466210760326565  & valid loss :  0.017675191164016724  & epoch :  61  & time 92.3911726474762\n",
      "best model save at NLinear.pt\n",
      "train loss :  0.01746619628715569  & valid loss :  0.017675194889307022  & epoch :  62  & time 93.79536271095276\n",
      "train loss :  0.01746618920741983  & valid loss :  0.017675191164016724  & epoch :  63  & time 95.77161836624146\n",
      "train loss :  0.017466185691462816  & valid loss :  0.017675191164016724  & epoch :  64  & time 97.1947991847992\n",
      "train loss :  0.01746618638924043  & valid loss :  0.017675191164016724  & epoch :  65  & time 98.59198641777039\n",
      "train loss :  0.017466186050878442  & valid loss :  0.017675191164016724  & epoch :  66  & time 100.0136649608612\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1004)\n",
    "\n",
    "n_linear = Linear.NLinear(365*train_years,365)\n",
    "\n",
    "optimizer = AdamW(n_linear.parameters(), lr = 1e-2, eps = 1e-16)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience=0, verbose = True)\n",
    "start = time.time()\n",
    "best_loss = 0\n",
    "early_count = 0\n",
    "epoch = 0\n",
    "while((early_count < 5) & (time.time()-start < 1000)):\n",
    "    epoch += 1\n",
    "    losses = []\n",
    "    nums = []\n",
    "    for batch in train_loader:\n",
    "        last = batch[0][:,-1].clone().unsqueeze(1)\n",
    "        batch[0] /= last\n",
    "        batch[1] /= last\n",
    "        logits = n_linear(batch[0].float())\n",
    "        \n",
    "        loss, num = functions.get_loss(logits, batch[1].float(), nn.MSELoss(), optimizer)\n",
    "        losses.append(loss)\n",
    "        nums.append(num)\n",
    "    train_loss = np.sum(np.multiply(losses, nums))/np.sum(nums)\n",
    "\n",
    "    losses = []\n",
    "    nums = []\n",
    "    for batch in valid_loader:\n",
    "        last = batch[0][:,-1].clone().unsqueeze(1)\n",
    "        batch[0] /= last\n",
    "        batch[1] /= last\n",
    "        logits = n_linear(batch[0].float())\n",
    "        \n",
    "        loss, num = functions.get_loss(logits, batch[1].float(), nn.MSELoss(), optimizer)\n",
    "        losses.append(loss)\n",
    "        nums.append(num)\n",
    "    valid_loss = np.sum(np.multiply(losses, nums))/np.sum(nums)\n",
    "    scheduler.step(valid_loss)\n",
    "    \n",
    "    print('train loss : ', train_loss, ' & valid loss : ', valid_loss, ' & epoch : ', epoch, ' & time', time.time()-start)\n",
    "    \n",
    "    if best_loss == 0:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(n_linear, '../copy-of-forecasting-mini-course-sales/NLinear.pt')\n",
    "        print('best model save at NLinear.pt')\n",
    "    else:\n",
    "        if best_loss > valid_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(n_linear, '../copy-of-forecasting-mini-course-sales/NLinear.pt')\n",
    "            print('best model save at NLinear.pt')\n",
    "            early_count = 0\n",
    "        else:\n",
    "            early_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de97bfb",
   "metadata": {
    "papermill": {
     "duration": 0.033354,
     "end_time": "2024-03-26T08:41:06.974885",
     "exception": false,
     "start_time": "2024-03-26T08:41:06.941531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "forsub = test.sort_values(['country','store','product', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "847076e5",
   "metadata": {
    "papermill": {
     "duration": 0.024192,
     "end_time": "2024-03-26T08:41:07.013674",
     "exception": false,
     "start_time": "2024-03-26T08:41:06.989482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last = test_feature[:,-1].clone().unsqueeze(1)\n",
    "test_feature_scaled = test_feature / last ## scaling을 진행하지 않는 것이 좋게 나온다. 왜지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3567b3ec",
   "metadata": {
    "papermill": {
     "duration": 0.048255,
     "end_time": "2024-03-26T08:41:07.076433",
     "exception": false,
     "start_time": "2024-03-26T08:41:07.028178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>136960</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239.380264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>137035</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.390228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>137110</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.368896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>137185</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212.097107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>137260</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205.316177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27069</th>\n",
       "      <td>164019</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>88.817276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27144</th>\n",
       "      <td>164094</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>98.842087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27219</th>\n",
       "      <td>164169</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>109.833572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27294</th>\n",
       "      <td>164244</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>119.414207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27369</th>\n",
       "      <td>164319</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>120.877182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date  country  store  product    num_sold\n",
       "10     136960 2022-01-01        0      0        0  239.380264\n",
       "85     137035 2022-01-02        0      0        0  248.390228\n",
       "160    137110 2022-01-03        0      0        0  211.368896\n",
       "235    137185 2022-01-04        0      0        0  212.097107\n",
       "310    137260 2022-01-05        0      0        0  205.316177\n",
       "...       ...        ...      ...    ...      ...         ...\n",
       "27069  164019 2022-12-27        4      2        4   88.817276\n",
       "27144  164094 2022-12-28        4      2        4   98.842087\n",
       "27219  164169 2022-12-29        4      2        4  109.833572\n",
       "27294  164244 2022-12-30        4      2        4  119.414207\n",
       "27369  164319 2022-12-31        4      2        4  120.877182\n",
       "\n",
       "[27375 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_linear = torch.load('../copy-of-forecasting-mini-course-sales/NLinear.pt')\n",
    "forsub['num_sold'] = [abs(x) for x in n_linear(test_feature.float()).reshape(-1).tolist()]\n",
    "forsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c8474a",
   "metadata": {
    "papermill": {
     "duration": 0.050282,
     "end_time": "2024-03-26T08:41:07.141583",
     "exception": false,
     "start_time": "2024-03-26T08:41:07.091301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = pd.read_csv('../copy-of-forecasting-mini-course-sales/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05fcc31",
   "metadata": {
    "papermill": {
     "duration": 0.121616,
     "end_time": "2024-03-26T08:41:07.278571",
     "exception": false,
     "start_time": "2024-03-26T08:41:07.156955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions.index = submissions.id\n",
    "forsub.index = forsub.id\n",
    "pd.concat([submissions[['id']], forsub[['num_sold']]], axis=1).to_csv('../copy-of-forecasting-mini-course-sales/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7913550,
     "sourceId": 72259,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 192.029398,
   "end_time": "2024-03-26T08:41:09.420692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-26T08:37:57.391294",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
